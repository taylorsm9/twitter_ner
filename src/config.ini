
[MODEL]
# Model type
# Values accepted:
# 0: BERT
# 1: BERTweet
MODEL_TYPE = 1

[DATA]
# Dataset
# Values accepted:
# 0: BERT
# 1: BERTweet
DATASET = 1

[TRAINING]
MAX_LEN = 128
# A larger batch size will make training go faster, but too large will use all
# available memory and throw an error Trial and error will be needed to find an
# optimal batch size depending on hardware. A batch size of 6 was sufficient to
# complete epochs in under 2 minutes on a laptop, a batch size of 32 may
# take up to 60 minutes per epoch on colab.

TRAIN_BATCH_SIZE = 8
TEST_BATCH_SIZE = 8

# More Epochs can improve performance, or cause overfitting.
EPOCHS = 2

#Path to save trained models
MODEL_PATH = 'twitter_ner/models/'
